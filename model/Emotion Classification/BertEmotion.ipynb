{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49769,"status":"ok","timestamp":1659198402356,"user":{"displayName":"tan wan","userId":"06209479695706955034"},"user_tz":-60},"id":"JFmNlxViX-nv","outputId":"0c155802-da79-481c-e9c4-f9a5a87c2ee1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 13.4 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 52.0 MB/s \n","\u001b[?25hCollecting datasets\n","  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n","\u001b[K     |████████████████████████████████| 365 kB 60.9 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 50.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 60.4 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 8.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting fsspec[http]>=2021.11.1\n","  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n","\u001b[K     |████████████████████████████████| 141 kB 52.1 MB/s \n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 52.0 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 49.3 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: urllib3, pyyaml, fsspec, xxhash, tokenizers, responses, huggingface-hub, transformers, sentencepiece, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed datasets-2.4.0 fsspec-2022.7.1 huggingface-hub-0.8.1 pyyaml-6.0 responses-0.18.0 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.21.0 urllib3-1.25.11 xxhash-3.0.0\n","Mounted at /content/gdrive/\n"]}],"source":["!pip install transformers sentencepiece datasets\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive/')\n","\n","import os\n","os.chdir('/content/gdrive/MyDrive/Individual Project')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":9643,"status":"ok","timestamp":1659198411992,"user":{"displayName":"tan wan","userId":"06209479695706955034"},"user_tz":-60},"id":"8X5nqX5aYLpi"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","from transformers import TrainingArguments, Trainer\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import EarlyStoppingCallback\n","from transformers import AutoTokenizer, AutoModelWithLMHead\n","from tokenizers import BertWordPieceTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fgS7enRvYC-w"},"outputs":[],"source":["#create a dictionary which associates each string label to an integer value\n","labels = [ \"no\", \"weak\", \"strong\"]\n","label2int = dict(zip(labels, list(range(len(labels)))))"]},{"cell_type":"markdown","metadata":{"id":"7ecGjD5QYVP7"},"source":["# Start building classifier"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5528,"status":"ok","timestamp":1659198417516,"user":{"displayName":"tan wan","userId":"06209479695706955034"},"user_tz":-60},"id":"DjqbzwhRYJ3F","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["35cbbb9dd501497aacad2effe1d59de0","94ceb866ea374dcab4283e437c70aaf5","d722f6e33793481e93b2695675121ca1","11304e7925cc4403b7a1160bba31d04e","6ae50ec5bd96475c852ab84d3ce87661","2c0b2119ff8343d7a945fb14ea058c41","884b0a0ec9c34254b3f2425b153f7743","716f26a82a8b4b7dbc1e1342f1ef9a28","463942df1e2246938a6f4c64e1d3f0ea","bc86c6bed7bb40739acc8fdfed5839e8","975688fafc6e4a849c6667cf0d2e4eaf","7ee28f0b656f47139a76b921c7beb3b2","85b3f9b5c9954655ad25c59316d751da","6fa0c5a83e374ab981a170944be0bc6a","a97d017cf8d8483a91143a12741b7ea9","a4569265871c4bfebcea9f429caa18f3","8933d5450d0b455f8c01c2f902f6b6f1","d685e760a4654d86a08eecfc76d5ee20","04a1d676df6648729beeb2b047997e82","1ef398ebc5754778aa22a4d57e823541","82bbe6841fc94e1d9c5bde6321c54a08","228f277285934d66a1de34bdca823ac8","89eb33e6e3a142f1ae6714cb7fd40882","b5154b7093d44f929292833349a30544","aec47395a32a45aeb147e71916dfad39","f3e06a7ff403410bb3686fdfbd25e132","f80f3b8f294f4ac19817c27c8e844ba3","138f1281aa3c433ea70d4e3d828ee994","2121abb84f9c4886b7957ca4baf05a73","ba3907e5c2544446ae5c5115c659e125","2294e6463c7e407b9ad134723663be7d","19144866f6614d318aaee698363c04e7","edfaa5fbe7d04c8fa29a58ca3f9ef4d9","9b7b0edf03704e72a3cf282142c57cba","c6dd5d5c94a049079bf407eba8b6e10e","5a3ffccb6f9d431998f9aeb1a5cfc0d0","1cc6cf04457c4750a799d54022515181","1505e3323e224cc5aed467851bba5108","cf1b207cf67d43b799a18b5040352f9d","6c1e32d3df04435bbb992011007bf3c8","0e0a05e59b8f43cfbd86d6585357f72f","3ef1b82bf98c4cdba38be968bb60faf3","967aabf759d341018b8eb5797bd97c71","0561530d7f0048ba9e81643a5d878eeb"]},"outputId":"45ab2600-2c6a-4e16-f379-a74ebc4f0046"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35cbbb9dd501497aacad2effe1d59de0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/624 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ee28f0b656f47139a76b921c7beb3b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.txt:   0%|          | 0.00/107k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89eb33e6e3a142f1ae6714cb7fd40882"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer.json:   0%|          | 0.00/263k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b7b0edf03704e72a3cf282142c57cba"}},"metadata":{}}],"source":["from transformers import AutoTokenizer\n","\n","model_checkpoint = \"bert-base-chinese\"\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1659196796856,"user":{"displayName":"Hee Ha","userId":"11664360853934259491"},"user_tz":-60},"id":"rLldnDjWYOjb","outputId":"5c23bff0-c1f1-4114-e0c8-4879ac04cf50"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [101, 2769, 5445, 2157, 1962, 100, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":11}],"source":["encoded_str = tokenizer(\"我而家好嬲\")\n","encoded_str"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9002,"status":"ok","timestamp":1659198447788,"user":{"displayName":"tan wan","userId":"06209479695706955034"},"user_tz":-60},"id":"7sWxclJLYY0t"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification\n","\n","num_labels = 4\n","model = AutoModelForSequenceClassification.from_pretrained(\"/content/gdrive/MyDrive/Individual Project/EmotionClassification/BERT/BERTLarge\", num_labels=num_labels)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":478},"executionInfo":{"elapsed":304616,"status":"ok","timestamp":1659198752401,"user":{"displayName":"tan wan","userId":"06209479695706955034"},"user_tz":-60},"id":"dLblyg_GY1NQ","outputId":"e83f1eda-4d42-46bb-98ac-d3fffc7718b6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1740/1740 04:54, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.509389</td>\n","      <td>0.828704</td>\n","      <td>0.828704</td>\n","      <td>0.828704</td>\n","      <td>0.828704</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.539740</td>\n","      <td>0.810185</td>\n","      <td>0.810185</td>\n","      <td>0.810185</td>\n","      <td>0.810185</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.424100</td>\n","      <td>0.679999</td>\n","      <td>0.842593</td>\n","      <td>0.842593</td>\n","      <td>0.842593</td>\n","      <td>0.842593</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.424100</td>\n","      <td>0.774725</td>\n","      <td>0.824074</td>\n","      <td>0.824074</td>\n","      <td>0.824074</td>\n","      <td>0.824074</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.424100</td>\n","      <td>0.774996</td>\n","      <td>0.833333</td>\n","      <td>0.833333</td>\n","      <td>0.833333</td>\n","      <td>0.833333</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.152500</td>\n","      <td>0.809780</td>\n","      <td>0.842593</td>\n","      <td>0.842593</td>\n","      <td>0.842593</td>\n","      <td>0.842593</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.152500</td>\n","      <td>0.880337</td>\n","      <td>0.828704</td>\n","      <td>0.828704</td>\n","      <td>0.828704</td>\n","      <td>0.828704</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.152500</td>\n","      <td>0.885449</td>\n","      <td>0.833333</td>\n","      <td>0.833333</td>\n","      <td>0.833333</td>\n","      <td>0.833333</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.052300</td>\n","      <td>0.889652</td>\n","      <td>0.851852</td>\n","      <td>0.851852</td>\n","      <td>0.851852</td>\n","      <td>0.851852</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.052300</td>\n","      <td>0.916457</td>\n","      <td>0.828704</td>\n","      <td>0.828704</td>\n","      <td>0.828704</td>\n","      <td>0.828704</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1740, training_loss=0.18597575604230507, metrics={'train_runtime': 297.5726, 'train_samples_per_second': 58.204, 'train_steps_per_second': 5.847, 'total_flos': 498439955919360.0, 'train_loss': 0.18597575604230507, 'epoch': 10.0})"]},"metadata":{},"execution_count":5}],"source":["import torch\n","\n","from transformers import TrainingArguments\n","\n","\n","args = TrainingArguments(\n","    output_dir=\"/content/gdrive/MyDrive/Individual Project/Model\",\n","    num_train_epochs=10,\n","    learning_rate =1e-5,\n","    adam_epsilon=1e-06,\n","    per_device_train_batch_size=10,\n","    per_device_eval_batch_size=10,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy='epoch',\n","    disable_tqdm=False,\n","    eval_steps=500,\n","    logging_steps=500,\n","    log_level='error',\n","    save_total_limit = 2,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='accuracy',\n","    overwrite_output_dir=False,\n",")\n","\n","\n","def compute_metrics(p):\n","    pred, labels = p\n","    pred = np.argmax(pred, axis=1)\n","\n","    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","    recall = recall_score(y_true=labels, y_pred=pred, average='micro')\n","    precision = precision_score(y_true=labels, y_pred=pred, average='micro')\n","    f1 = f1_score(y_true=labels, y_pred=pred, average='micro')\n","\n","    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n","\n","data = pd.read_csv(\"/content/gdrive/MyDrive/Individual Project/Merge_CantoneseEmotion_ds.csv\")\n","\n","# ----- 1. Preprocess data -----#\n","# Preprocess data\n","X = list(data[\"content\"])\n","y = list(data[\"label\"])\n","# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n","\n","train_ratio = 0.80\n","validation_ratio = 0.10\n","test_ratio = 0.10\n","\n","# train is now 75% of the entire data set\n","# the _junk suffix means that we drop that variable completely\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - train_ratio, random_state=0)\n","\n","# test is now 10% of the initial data set\n","# validation is now 15% of the initial data set\n","X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=0) \n","\n","X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n","X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n","X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n","\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels=None):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        if self.labels:\n","            item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.encodings[\"input_ids\"])\n","\n","train_dataset = Dataset(X_train_tokenized, y_train)\n","val_dataset = Dataset(X_val_tokenized, y_val)\n","test_dataset=Dataset(X_test_tokenized, y_test)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n","    # callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n","    # callbacks=checkpoint_callback,\n",")\n","\n","# Train pre-trained model\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1659060950128,"user":{"displayName":"Hee Ha","userId":"11664360853934259491"},"user_tz":-60},"id":"jPs-IsPdzJPV","outputId":"67a2cf31-57bb-444a-8b70-3a66795a9e72"},"outputs":[{"data":{"text/plain":["PreTrainedTokenizerFast(name_or_path='hfl/chinese-roberta-wwm-ext', vocab_size=21128, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2073,"status":"ok","timestamp":1659198756281,"user":{"displayName":"tan wan","userId":"06209479695706955034"},"user_tz":-60},"id":"ndl6iTs4b4wr"},"outputs":[],"source":["trainer.save_model(\"/content/gdrive/MyDrive/Individual Project/EmotionClassification/BERT/BERTMerge2\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4315,"status":"ok","timestamp":1659198766314,"user":{"displayName":"tan wan","userId":"06209479695706955034"},"user_tz":-60},"id":"eZtFrk4fcGTv","outputId":"c3983963-11c6-4d40-e9c0-0c28aa9e11e5"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 217\n","  Batch size = 8\n"]}],"source":["# ----- 3. Predict -----#\n","# Load test data\n","# test_data = pd.read_csv(\"test.csv\")\n","# X_test = list(test_data[\"review\"])\n","# X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n","\n","# Create torch dataset\n","# test_dataset = Dataset(X_test_tokenized)\n","\n","# Load trained model\n","model_path = \"/content/gdrive/MyDrive/Individual Project/EmotionClassification/BERT/BERTMerge2\"\n","model = BertForSequenceClassification.from_pretrained(model_path, num_labels=4)\n","\n","# Define test trainer\n","test_trainer = Trainer(model)\n","\n","# Make prediction \n","raw_pred, _, _ = test_trainer.predict(test_dataset)\n","\n","# Preprocess raw predictions\n","y_pred = np.argmax(raw_pred, axis=1)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":330,"status":"ok","timestamp":1659198780368,"user":{"displayName":"tan wan","userId":"06209479695706955034"},"user_tz":-60},"id":"5w36-ZkIcIP5","outputId":"9ed42c1f-a460-47ec-a272-09cdbbf2ec7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0     0.7910    0.8983    0.8413        59\n","           1     0.8750    0.7368    0.8000        57\n","           2     0.8125    0.8125    0.8125        48\n","           3     0.9259    0.9434    0.9346        53\n","\n","    accuracy                         0.8479       217\n","   macro avg     0.8511    0.8478    0.8471       217\n","weighted avg     0.8508    0.8479    0.8469       217\n","\n"]}],"source":["from sklearn import metrics\n","\n","print(metrics.classification_report(y_test, y_pred, digits=4))"]},{"cell_type":"code","source":["   # ----- 3. Predict -----#\n","model_path = \"/content/gdrive/MyDrive/Individual Project/EmotionClassification/BERT/BERTMerge2\"\n","model = BertForSequenceClassification.from_pretrained(model_path, num_labels=4)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n","\n","text = \"ok la\"\n","# tokenizer2 = BertTokenizer.from_pretrained('bert-base-chinese')\n","X_test_tokenized = tokenizer(text, padding=True, truncation=True, max_length=512)\n","\n","b_input_ids= torch.tensor(X_test_tokenized['input_ids']).unsqueeze(0)\n","b_attention_mask = torch.tensor(X_test_tokenized['attention_mask']).unsqueeze(0)\n","\n","with torch.no_grad():\n","    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_attention_mask)\n","\n","logits = outputs[0]\n","print(logits)\n","logits = logits.detach().numpy()\n","predict_label = np.argmax(logits, axis=1).flatten()\n","print(predict_label)\n","\n","label = \" \"\n","\n","for i in predict_label:\n","    if i == 0:\n","        label = \"唔開心\"\n","    elif i == 1:\n","        label = \"嬲\"\n","    elif i == 2:\n","        label = \"擔心\"\n","    else:\n","        label = \"開心\"\n","print(label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KQGiVa35Mz9G","executionInfo":{"status":"ok","timestamp":1659198804009,"user_tz":-60,"elapsed":7862,"user":{"displayName":"tan wan","userId":"06209479695706955034"}},"outputId":"29d0264b-4aeb-42f7-be0f-9e60f5c7080e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file /content/gdrive/MyDrive/Individual Project/EmotionClassification/BERT/BERTMerge2/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/gdrive/MyDrive/Individual Project/EmotionClassification/BERT/BERTLarge\",\n","  \"architectures\": [\n","    \"BertForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.21.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 21128\n","}\n","\n","loading weights file /content/gdrive/MyDrive/Individual Project/EmotionClassification/BERT/BERTMerge2/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForSequenceClassification.\n","\n","All the weights of BertForSequenceClassification were initialized from the model checkpoint at /content/gdrive/MyDrive/Individual Project/EmotionClassification/BERT/BERTMerge2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n","loading file https://huggingface.co/bert-base-chinese/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/36acdf4f3edf0a14ffb2b2c68ba47e93abd9448825202377ddb16dae8114fe07.accd894ff58c6ff7bd4f3072890776c14f4ea34fcc08e79cd88c2d157756dceb\n","loading file https://huggingface.co/bert-base-chinese/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-chinese/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-chinese/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/2dc6085404c55008ba7fc09ab7483ef3f0a4ca2496ccee0cdbf51c2b5d529dff.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","loading configuration file https://huggingface.co/bert-base-chinese/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6cc404ca8136bc87bae0fb24f2259904943d776a6c5ddc26598bbdc319476f42.0f9bcd8314d841c06633e7b92b04509f1802c16796ee67b0f1177065739e24ae\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-chinese\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.21.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 21128\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["tensor([[ 0.0951, -2.6707, -0.5865,  3.3913]])\n","[3]\n","開心\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"id":"-xZeBht5cL9s","executionInfo":{"status":"ok","timestamp":1659198873554,"user_tz":-60,"elapsed":3232,"user":{"displayName":"tan wan","userId":"06209479695706955034"}}},"outputs":[],"source":["torch.save(model.state_dict(), '/content/gdrive/MyDrive/Individual Project/EmotionClassification/BERT/BestBERTEmotion/BestBERTEmotion.pt')"]},{"cell_type":"markdown","metadata":{"id":"DLgXG4-4RXX1"},"source":["# Roy's"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dTiI7v79RYeb"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from transformers.models.bert.modeling_bert import BertPreTrainedModel\n","\n","class EmotionClassifier(nn.Module):\n","    \"\"\"\n","        Classifier Head for the EmotionClassifierModule\n","        Takes input of (batch_size, hidden_size) and outputs to num_labels\n","    \"\"\"\n","    def __init__(self, args):\n","        super(EmotionClassifier, self).__init__()\n","        self.layers = nn.Sequential(\n","            nn.Dropout(args.dropout),\n","            nn.Linear(args.hidden_size, args.hidden_size),\n","            nn.ReLU(),\n","            nn.Dropout(args.dropout),\n","            nn.Linear(args.hidden_size, args.num_labels),\n","        )\n","\n","    def forward(self, x):\n","        return self.layers(x)\n","\n","\n","class EmotionClassifierModule(BertPreTrainedModel):\n","    \"\"\"\n","      Model wrapper used to classify a given utterance into a known emotion class\n","    \"\"\"\n","    def __init__(self, config, args, model_type):\n","        super(EmotionClassifierModule, self).__init__(config)\n","        self.args = args\n","        # Can either load a saved pytorch model or a pre-trained HuggingFace model\n","        if not args.load_model:\n","            self.roberta = model_type.from_pretrained(args.model_type)\n","        elif args.load_pretrained == 'hf':\n","            self.roberta = model_type.from_pretrained(args.load_model)\n","        # Create Classifier Head\n","        self.classifier = EmotionClassifier(args)\n","\n","    def forward(self, input_ids, attention_mask, emotion_labels=None, alignment_set=None):\n","        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n","        # Select [CLS] embedding and perform classification\n","        pooled = outputs['pooler_output']\n","        emotion_logits = self.classifier(pooled)\n","\n","        tar_pooled = None\n","        # Generate [CLS] embedding for alignment set if performing cross-lingual alignment\n","        if alignment_set is not None:\n","            tar_ids = alignment_set[:, 0]\n","            tar_mask = alignment_set[:, 1]\n","            tar_pooled = self.roberta(input_ids=tar_ids, attention_mask=tar_mask)['pooler_output']\n","\n","        loss = None\n","        if self.training and emotion_labels is not None:\n","            # Task loss\n","            loss_fn = F.cross_entropy\n","            loss = loss_fn(emotion_logits, emotion_labels)\n","\n","            # Contrastive loss\n","            if alignment_set is not None:\n","                sim_logits = pooled / torch.norm(pooled, dim=1).reshape((-1, 1))\n","                tar_logits = tar_pooled / torch.norm(tar_pooled, dim=1).reshape((-1, 1))\n","                sim = torch.matmul(sim_logits, tar_logits.T)\n","                mask = (emotion_labels != emotion_labels.reshape((-1, 1))).float().to(self.args.device)\n","                mask += torch.diag(torch.ones(input_ids.size(0))).to(self.args.device)\n","                sim = sim * mask\n","\n","                loss_ctr = loss_fn(sim, torch.arange(input_ids.size(0)).to(self.args.device))\n","                loss += loss_ctr\n","\n","        return emotion_logits, loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AMs7xUS9RhW9"},"outputs":[],"source":["model = torch.load(\"\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"BertEmotion.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"35cbbb9dd501497aacad2effe1d59de0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94ceb866ea374dcab4283e437c70aaf5","IPY_MODEL_d722f6e33793481e93b2695675121ca1","IPY_MODEL_11304e7925cc4403b7a1160bba31d04e"],"layout":"IPY_MODEL_6ae50ec5bd96475c852ab84d3ce87661"}},"94ceb866ea374dcab4283e437c70aaf5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c0b2119ff8343d7a945fb14ea058c41","placeholder":"​","style":"IPY_MODEL_884b0a0ec9c34254b3f2425b153f7743","value":"Downloading tokenizer_config.json: 100%"}},"d722f6e33793481e93b2695675121ca1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_716f26a82a8b4b7dbc1e1342f1ef9a28","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_463942df1e2246938a6f4c64e1d3f0ea","value":29}},"11304e7925cc4403b7a1160bba31d04e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc86c6bed7bb40739acc8fdfed5839e8","placeholder":"​","style":"IPY_MODEL_975688fafc6e4a849c6667cf0d2e4eaf","value":" 29.0/29.0 [00:00&lt;00:00, 269B/s]"}},"6ae50ec5bd96475c852ab84d3ce87661":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c0b2119ff8343d7a945fb14ea058c41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"884b0a0ec9c34254b3f2425b153f7743":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"716f26a82a8b4b7dbc1e1342f1ef9a28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"463942df1e2246938a6f4c64e1d3f0ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc86c6bed7bb40739acc8fdfed5839e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"975688fafc6e4a849c6667cf0d2e4eaf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ee28f0b656f47139a76b921c7beb3b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85b3f9b5c9954655ad25c59316d751da","IPY_MODEL_6fa0c5a83e374ab981a170944be0bc6a","IPY_MODEL_a97d017cf8d8483a91143a12741b7ea9"],"layout":"IPY_MODEL_a4569265871c4bfebcea9f429caa18f3"}},"85b3f9b5c9954655ad25c59316d751da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8933d5450d0b455f8c01c2f902f6b6f1","placeholder":"​","style":"IPY_MODEL_d685e760a4654d86a08eecfc76d5ee20","value":"Downloading config.json: 100%"}},"6fa0c5a83e374ab981a170944be0bc6a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_04a1d676df6648729beeb2b047997e82","max":624,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ef398ebc5754778aa22a4d57e823541","value":624}},"a97d017cf8d8483a91143a12741b7ea9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82bbe6841fc94e1d9c5bde6321c54a08","placeholder":"​","style":"IPY_MODEL_228f277285934d66a1de34bdca823ac8","value":" 624/624 [00:00&lt;00:00, 17.2kB/s]"}},"a4569265871c4bfebcea9f429caa18f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8933d5450d0b455f8c01c2f902f6b6f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d685e760a4654d86a08eecfc76d5ee20":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04a1d676df6648729beeb2b047997e82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ef398ebc5754778aa22a4d57e823541":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"82bbe6841fc94e1d9c5bde6321c54a08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"228f277285934d66a1de34bdca823ac8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89eb33e6e3a142f1ae6714cb7fd40882":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5154b7093d44f929292833349a30544","IPY_MODEL_aec47395a32a45aeb147e71916dfad39","IPY_MODEL_f3e06a7ff403410bb3686fdfbd25e132"],"layout":"IPY_MODEL_f80f3b8f294f4ac19817c27c8e844ba3"}},"b5154b7093d44f929292833349a30544":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_138f1281aa3c433ea70d4e3d828ee994","placeholder":"​","style":"IPY_MODEL_2121abb84f9c4886b7957ca4baf05a73","value":"Downloading vocab.txt: 100%"}},"aec47395a32a45aeb147e71916dfad39":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba3907e5c2544446ae5c5115c659e125","max":109540,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2294e6463c7e407b9ad134723663be7d","value":109540}},"f3e06a7ff403410bb3686fdfbd25e132":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19144866f6614d318aaee698363c04e7","placeholder":"​","style":"IPY_MODEL_edfaa5fbe7d04c8fa29a58ca3f9ef4d9","value":" 107k/107k [00:00&lt;00:00, 168kB/s]"}},"f80f3b8f294f4ac19817c27c8e844ba3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"138f1281aa3c433ea70d4e3d828ee994":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2121abb84f9c4886b7957ca4baf05a73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba3907e5c2544446ae5c5115c659e125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2294e6463c7e407b9ad134723663be7d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19144866f6614d318aaee698363c04e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edfaa5fbe7d04c8fa29a58ca3f9ef4d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b7b0edf03704e72a3cf282142c57cba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6dd5d5c94a049079bf407eba8b6e10e","IPY_MODEL_5a3ffccb6f9d431998f9aeb1a5cfc0d0","IPY_MODEL_1cc6cf04457c4750a799d54022515181"],"layout":"IPY_MODEL_1505e3323e224cc5aed467851bba5108"}},"c6dd5d5c94a049079bf407eba8b6e10e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf1b207cf67d43b799a18b5040352f9d","placeholder":"​","style":"IPY_MODEL_6c1e32d3df04435bbb992011007bf3c8","value":"Downloading tokenizer.json: 100%"}},"5a3ffccb6f9d431998f9aeb1a5cfc0d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e0a05e59b8f43cfbd86d6585357f72f","max":268943,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ef1b82bf98c4cdba38be968bb60faf3","value":268943}},"1cc6cf04457c4750a799d54022515181":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_967aabf759d341018b8eb5797bd97c71","placeholder":"​","style":"IPY_MODEL_0561530d7f0048ba9e81643a5d878eeb","value":" 263k/263k [00:00&lt;00:00, 705kB/s]"}},"1505e3323e224cc5aed467851bba5108":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf1b207cf67d43b799a18b5040352f9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c1e32d3df04435bbb992011007bf3c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e0a05e59b8f43cfbd86d6585357f72f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ef1b82bf98c4cdba38be968bb60faf3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"967aabf759d341018b8eb5797bd97c71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0561530d7f0048ba9e81643a5d878eeb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}